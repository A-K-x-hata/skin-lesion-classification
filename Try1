# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PXwXMgvnQWS4UJdNyEokPYWonf877v6X
"""

from google.colab import drive
drive.mount('/content/drive')

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import os
from glob import glob
import seaborn as sns
from PIL import Image

np.random.seed(42)
from sklearn.metrics import confusion_matrix

import keras
from keras.utils import to_categorical
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization
from sklearn.model_selection import train_test_split
from scipy import stats
from sklearn.preprocessing import LabelEncoder

skin_df = pd.read_csv("/content/drive/MyDrive/skin lesion/data/HAM10000/HAM10000_metadata.csv")

skin_df.head()

SIZE=32

le=LabelEncoder()
le.fit(skin_df['dx'])
LabelEncoder()
print(list(le.classes_))

skin_df['label'] = le.transform(skin_df["dx"])
print(skin_df.sample(10))

fig = plt.figure(figsize=(15,10))

ax1=fig.add_subplot(221)
skin_df['dx'].value_counts().plot(kind='bar')
ax1.set_ylabel('Count')
ax1.set_title('cell Type')

ax2=fig.add_subplot(222)
skin_df['sex'].value_counts().plot(kind='bar')
ax2.set_ylabel('Count',size=15)
ax2.set_title('Sex')

ax3=fig.add_subplot(223)
skin_df['localization'].value_counts().plot(kind='bar')
ax3.set_ylabel('Count',size=12)
ax3.set_title('Localization')

ax4=fig.add_subplot(224)
sample_age=skin_df[pd.notnull(skin_df['age'])]
sns.distplot(sample_age['age'],fit=stats.norm,color='red')
ax4.set_title('Age')

df_0 = skin_df[skin_df['label']==0]
df_1 = skin_df[skin_df['label']==1]
df_2 = skin_df[skin_df['label']==2]
df_3 = skin_df[skin_df['label']==3]
df_4 = skin_df[skin_df['label']==4]
df_5 = skin_df[skin_df['label']==5]
df_6 = skin_df[skin_df['label']==6]

from sklearn.utils import resample
print(skin_df['label'].value_counts())

n_samples=500
df_0_balanced = resample(df_0,replace=True,n_samples=n_samples,random_state=0)
df_1_balanced = resample(df_1,replace=True,n_samples=n_samples,random_state=0)
df_2_balanced = resample(df_2,replace=True,n_samples=n_samples,random_state=0)
df_3_balanced = resample(df_3,replace=True,n_samples=n_samples,random_state=0)
df_4_balanced = resample(df_4,replace=True,n_samples=n_samples,random_state=0)
df_5_balanced = resample(df_5,replace=True,n_samples=n_samples,random_state=0)
df_6_balanced = resample(df_6,replace=True,n_samples=n_samples,random_state=0)

skin_df_balanced = pd.concat([df_0_balanced,df_1_balanced,df_2_balanced,df_3_balanced,df_4_balanced,df_5_balanced,df_6_balanced])

print(skin_df_balanced['label'].value_counts())

image_path = {os.path.splitext(os.path.basename(x))[0]: x for x in  glob(os.path.join("/content/drive/MyDrive/skin lesion/data/HAM10000/HAM10000_images_part_1", '*.jpg'))}

image_path

skin_df_balanced['path'] = skin_df['image_id'].map(image_path.get)

skin_df_balanced['image'] = skin_df['path'].map(lambda x: np.array(Image.open(x).resize((SIZE, SIZE))))

skin_df_balanced['image'].head()

skin_df_balanced.head()

"""Plotting the graphs"""

n_samples = 5
fig, m_axs = plt.subplots(7, n_samples, figsize=(4 * n_samples, 3 * 7))
for (type_name, type_rows), n_axs in zip(skin_df_balanced.sort_values(['dx']).groupby('dx'), m_axs):
    n_axs[0].set_title(type_name)
    for c_ax, (_, c_row) in zip(n_axs, type_rows.sample(n_samples, random_state=1234).iterrows()):
        c_ax.imshow(c_row['image'])
        c_ax.axis('off')

X=np.asarray(skin_df_balanced['image'].tolist())
X=X/255
Y=skin_df_balanced['label']
Y_cat=to_categorical(Y,num_classes=7)
x_train,x_test,y_train,y_test=train_test_split(X,Y_cat,test_size=0.25,random_state=0)

X

num_classes=7

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense
from tensorflow.keras.optimizers import Adam
model=Sequential()
model.add(Conv2D(256,(3,3),activation='relu',input_shape=(SIZE,SIZE,3)))
model.add(MaxPool2D(pool_size=(2,2)))
model.add(Dropout(0.3))
model.add(Conv2D(128,(3,3),activation='relu'))
model.add(MaxPool2D(pool_size=(2,2)))
model.add(Dropout(0.3))
model.add(Conv2D(64,(3,3),activation='relu'))
model.add(MaxPool2D(pool_size=(2,2)))
model.add(Dropout(0.3))
model.add(Flatten())
model.add(Dense(32))
model.add(Dense(7,activation='softmax'))
model.summary()
model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['acc'])

batch_size = 16
epochs = 50

history = model.fit(x_train, y_train,
                    epochs=epochs,
                    batch_size=batch_size,
                    validation_data=(x_test, y_test),
                    verbose=2)

score = model.evaluate(x_test, y_test)
print('Test accuracy:', score[1])

loss = history.history['loss']
val_loss = history.history['val_loss']
epochs_range = range(1, len(loss) + 1)

plt.plot(epochs_range, loss, 'y', label='Training loss')
plt.plot(epochs_range, val_loss, 'r', label='Validation loss')

plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()

